{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc9fcbc-ada9-4756-990c-ca708f6a6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58d2686-dbab-41c5-b4a4-de7c360cee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>state</th>\n",
       "      <th>apmc</th>\n",
       "      <th>commodity</th>\n",
       "      <th>min_price</th>\n",
       "      <th>modal_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>commodity_arrivals</th>\n",
       "      <th>commodity_traded</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>SAWAI MADHOPUR</td>\n",
       "      <td>URAD (BLACK GRAM)</td>\n",
       "      <td>61.55</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.55</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>SIKAR</td>\n",
       "      <td>GINGER</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>RAJSAMAND</td>\n",
       "      <td>SPINACH (PALAK)</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>600.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>RAJSAMAND</td>\n",
       "      <td>FENUGREEK (HARI METHI)</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>RAJASTHAN</td>\n",
       "      <td>RAJSAMAND</td>\n",
       "      <td>BRINJAL</td>\n",
       "      <td>19.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202290</th>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>ODISHA</td>\n",
       "      <td>BARIPADA</td>\n",
       "      <td>RIDGE GOURD (TURAI)</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202291</th>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>ODISHA</td>\n",
       "      <td>BARIPADA</td>\n",
       "      <td>BOTTLE GOURDE</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202292</th>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>HARYANA</td>\n",
       "      <td>SOHNA</td>\n",
       "      <td>ONION</td>\n",
       "      <td>17.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202293</th>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>HARYANA</td>\n",
       "      <td>SIRSA</td>\n",
       "      <td>ARBI (COLACASIA)</td>\n",
       "      <td>21.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202294</th>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>ODISHA</td>\n",
       "      <td>MALKANGIRI</td>\n",
       "      <td>PUMPKIN</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3202295 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_at      state            apmc               commodity  \\\n",
       "0        2021-01-01  RAJASTHAN  SAWAI MADHOPUR       URAD (BLACK GRAM)   \n",
       "1        2021-01-01  RAJASTHAN           SIKAR                  GINGER   \n",
       "2        2021-01-01  RAJASTHAN       RAJSAMAND         SPINACH (PALAK)   \n",
       "3        2021-01-01  RAJASTHAN       RAJSAMAND  FENUGREEK (HARI METHI)   \n",
       "4        2021-01-01  RAJASTHAN       RAJSAMAND                 BRINJAL   \n",
       "...             ...        ...             ...                     ...   \n",
       "3202290  2025-09-06     ODISHA        BARIPADA     RIDGE GOURD (TURAI)   \n",
       "3202291  2025-09-06     ODISHA        BARIPADA           BOTTLE GOURDE   \n",
       "3202292  2025-09-06    HARYANA           SOHNA                   ONION   \n",
       "3202293  2025-09-06    HARYANA           SIRSA        ARBI (COLACASIA)   \n",
       "3202294  2025-09-06     ODISHA      MALKANGIRI                 PUMPKIN   \n",
       "\n",
       "         min_price  modal_price  max_price  commodity_arrivals  \\\n",
       "0            61.55         65.0      65.55              4100.0   \n",
       "1            20.00         20.0      20.00               400.0   \n",
       "2             8.00          8.0       8.00               600.0   \n",
       "3             7.50          8.0       8.00               500.0   \n",
       "4            19.00         20.0      20.00               500.0   \n",
       "...            ...          ...        ...                 ...   \n",
       "3202290      40.00         40.0      40.00              1600.0   \n",
       "3202291      20.00         20.0      20.00              1600.0   \n",
       "3202292      17.00         18.0      20.00              1600.0   \n",
       "3202293      21.00         28.0      28.00              1600.0   \n",
       "3202294      15.00         15.0      15.00             20000.0   \n",
       "\n",
       "         commodity_traded  year  month  day  \n",
       "0                  4100.0  2021      1    1  \n",
       "1                   400.0  2021      1    1  \n",
       "2                   400.0  2021      1    1  \n",
       "3                   400.0  2021      1    1  \n",
       "4                   400.0  2021      1    1  \n",
       "...                   ...   ...    ...  ...  \n",
       "3202290            1600.0  2025      9    6  \n",
       "3202291            1600.0  2025      9    6  \n",
       "3202292            1600.0  2025      9    6  \n",
       "3202293            1600.0  2025      9    6  \n",
       "3202294           20000.0  2025      9    6  \n",
       "\n",
       "[3202295 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_output.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e12e97-8f20-4e41-8eab-8acfd62dc7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning for CSV files in: price_dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Where to save the JSON file (inside your frontend folder)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m OUTPUT_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrontend/apmc_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 75\u001b[0m \u001b[43mgenerate_apmc_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATASET_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_FILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mgenerate_apmc_mapping\u001b[0;34m(dataset_path, output_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç Scanning for CSV files in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # 1. Find all CSV files recursively\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# csv_files = glob.glob(os.path.join(dataset_path, \"**\", \"*.csv\"), recursive=True)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 2. Read only 'state' and 'apmc' columns from each file to save memory\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcsv_files\u001b[49m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# # Read specific columns. normalize casing if needed.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# df = pd.read_csv(file, usecols=['state', 'apmc'])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m# Ensure data is uppercase to match your HTML select values\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_files' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def generate_apmc_mapping(dataset_path, output_path):\n",
    "    \"\"\"\n",
    "    Reads CSV files from the dataset path, extracts unique State -> APMC mappings,\n",
    "    and saves them to a JSON file.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Scanning for CSV files in: {dataset_path}\")\n",
    "    \n",
    "    # # 1. Find all CSV files recursively\n",
    "    # csv_files = glob.glob(os.path.join(dataset_path, \"**\", \"*.csv\"), recursive=True)\n",
    "    \n",
    "    # if not csv_files:\n",
    "    #     print(\"‚ùå No CSV files found. Please check the path.\")\n",
    "    #     return\n",
    "\n",
    "    # all_data = []\n",
    "    \n",
    "    # print(f\"found {len(csv_files)} files. Processing...\")\n",
    "\n",
    "    # 2. Read only 'state' and 'apmc' columns from each file to save memory\n",
    "    # for file in csv_files:\n",
    "    #     try:\n",
    "    #         # # Read specific columns. normalize casing if needed.\n",
    "    #         # df = pd.read_csv(file, usecols=['state', 'apmc'])\n",
    "            \n",
    "    #         # # Drop duplicates immediately to keep list small\n",
    "    #         # df = df.drop_duplicates()\n",
    "            \n",
    "            # Ensure data is uppercase to match your HTML select values\n",
    "            df['state'] = df['state'].str.upper().str.strip()\n",
    "            df['apmc'] = df['apmc'].str.upper().str.strip()\n",
    "            \n",
    "            all_data.append(df)\n",
    "        except ValueError:\n",
    "            # Handle cases where columns might be named differently (e.g. 'State Name', 'Market')\n",
    "            # You can add logic here if your CSVs have inconsistent headers\n",
    "            print(f\"‚ö†Ô∏è  Skipping {os.path.basename(file)}: 'state' or 'apmc' columns not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error reading {os.path.basename(file)}: {e}\")\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"‚ùå No valid data extracted.\")\n",
    "        return\n",
    "\n",
    "    # 3. Combine and Group\n",
    "    print(\"üîÑ Combining data...\")\n",
    "    combined_df = pd.concat(all_data).drop_duplicates()\n",
    "    \n",
    "    # Create the dictionary { \"STATE\": [\"APMC1\", \"APMC2\", ...] }\n",
    "    print(\"mapping states to APMCs...\")\n",
    "    mapping = combined_df.groupby('state')['apmc'].apply(sorted).to_dict()\n",
    "    \n",
    "    # 4. Save to JSON\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(mapping, f, indent=4)\n",
    "        \n",
    "    print(f\"‚úÖ Success! JSON saved to: {output_path}\")\n",
    "    print(f\"üìä Extracted {len(mapping)} states and {sum(len(v) for v in mapping.values())} total APMCs.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- CONFIGURATION ---\n",
    "    # Path to your dataset folder containing the CSVs\n",
    "    DATASET_DIR = \"price_dataset\" \n",
    "    \n",
    "    # Where to save the JSON file (inside your frontend folder)\n",
    "    OUTPUT_FILE = \"frontend/apmc_data.json\"\n",
    "    \n",
    "    generate_apmc_mapping(DATASET_DIR, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e0600-96f1-4781-8231-8c75e2fab818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
